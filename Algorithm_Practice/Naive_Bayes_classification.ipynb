{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 6)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t2\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t2\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/\n",
    "\n",
    "News_Class_File = r\"C:\\Users\\nandpara\\PycharmProjects\\Machine_Learning1\\Stock_News_Analysis\\Clean_Data\\Cleaned_Files\\20181023_News_Class_File.csv\"\n",
    "News_Class = pd.read_csv(News_Class_File)\n",
    "MultiNB = MultinomialNB()\n",
    "# le = LabelEncoder()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "# News_Class_Df = News_Class.apply(le.fit_transform)\n",
    "counts = count_vect.fit(News_Class['News'])\n",
    "counts = count_vect.transform(News_Class['News'])\n",
    "print(count_vect)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'his', 'is', 'my', 'name', 'nandha', 'ram', 'ranjith']\n",
      "  (0, 5)\t0.657341001779919\n",
      "  (0, 4)\t0.43508727376583967\n",
      "  (0, 3)\t0.43508727376583967\n",
      "  (0, 2)\t0.43508727376583967\n",
      "  (1, 7)\t0.7418700560027411\n",
      "  (1, 4)\t0.38713857123192547\n",
      "  (1, 3)\t0.38713857123192547\n",
      "  (1, 2)\t0.38713857123192547\n",
      "  (2, 6)\t0.657341001779919\n",
      "  (2, 4)\t0.43508727376583967\n",
      "  (2, 3)\t0.43508727376583967\n",
      "  (2, 2)\t0.43508727376583967\n",
      "  (3, 6)\t0.33040166128896375\n",
      "  (3, 5)\t0.33040166128896375\n",
      "  (3, 4)\t0.4373789484260681\n",
      "  (3, 3)\t0.21868947421303406\n",
      "  (3, 2)\t0.4373789484260681\n",
      "  (3, 1)\t0.4190726125928692\n",
      "  (3, 0)\t0.4190726125928692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = transformer.fit(counts)\n",
    "feature = transformer.transform(counts)\n",
    "print(count_vect.get_feature_names())\n",
    "print(feature)\n",
    "MultiNB.fit(feature, News_Class['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAD' 'GOOD' 'VERY_BAD' 'VERY_GOOD']\n",
      "--->   (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['VERY_BAD'], dtype='<U9')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MultiNB.classes_)\n",
    "Predict_This = count_vect.transform(['his name is nandha'])\n",
    "print(\"--->\", Predict_This)\n",
    "Prdict_This = transformer.transform(Predict_This)\n",
    "print(Predict_This)\n",
    "MultiNB.predict(Prdict_This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21404633, 0.28412929, 0.28506259, 0.2167618 ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiNB.predict_proba(Prdict_This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
