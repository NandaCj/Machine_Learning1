{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis :\n",
    "\n",
    "## Dataset : \n",
    "    - Text File \n",
    "    - Amazon Product Review - Label followed by free text \n",
    "    - Two Classes \n",
    "        1. __label__1  --> Negative Review\n",
    "        2. __label__2  --> Positive Review\n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# sklearn imports \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Porter_Stemmer = PorterStemmer()\n",
    "WordNet_Lemmatizer = WordNetLemmatizer()\n",
    "cv = CountVectorizer(binary=True)\n",
    "lr_clf = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Files:\n",
    "Train_Data_File = 'kili_train_data.txt' \n",
    "Test_Data_File = 'kili_train_data.txt' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "    - Data is free text from customer i.e Natural language , hence data needs to be cleaned for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            labels                                           Features\n",
      "count        10010                                              10010\n",
      "unique           2                                              10010\n",
      "top     __label__1  Weak remake: I found this recent remake of the...\n",
      "freq          5103                                                  1\n",
      "            labels                                           Features\n",
      "count        10010                                              10010\n",
      "unique           2                                              10010\n",
      "top     __label__1  Weak remake: I found this recent remake of the...\n",
      "freq          5103                                                  1\n"
     ]
    }
   ],
   "source": [
    "# Load Train and Test Data \n",
    "\n",
    "df_train = pd.read_fwf(Train_Data_File, header = None)\n",
    "df_train = df_train.rename(columns={0:'labels', 1:'Features'}).drop(2, 1)\n",
    "\n",
    "\n",
    "df_test = pd.read_fwf(Test_Data_File, header = None)\n",
    "df_test = df_test.rename(columns={0:'labels', 1:'Features'}).drop(2, 1)\n",
    "\n",
    "\n",
    "print(df_train.describe())\n",
    "\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Labels for Better understanding \n",
    "# __label__1 = negative\n",
    "# __label__1 = positive\n",
    "\n",
    "df_train['labels'] = df_train['labels'].map({'__label__1': 'negative', '__label__2': 'positive'})\n",
    "df_test['labels'] = df_test['labels'].map({'__label__1': 'negative', '__label__2': 'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    cleaned_features = []\n",
    "    for index , line in enumerate(df['Features'].values):\n",
    "    #     print(index, line)\n",
    "        words = word_tokenize(line)\n",
    "        # remove Puntuations \n",
    "        words = [w.lower() for w in words if w not in string.punctuation]\n",
    "        words = [Porter_Stemmer.stem(w) for w in words if w not in stopwords.words('english') if w.isalpha() ]\n",
    "        words = [WordNet_Lemmatizer.lemmatize(w) for w in words ]\n",
    "        cleaned_features.append(\" \".join(words))\n",
    "    # Adding the cleaned_features to Dataframe\n",
    "    df['cleaned_features'] = pd.Series(cleaned_features)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     labels                                           Features  \\\n",
      "0  positive  Stuning even for the non-gamer: This sound tra...   \n",
      "1  positive  The best soundtrack ever to anything.: I'm rea...   \n",
      "2  positive  Amazing!: This soundtrack is my favorite music...   \n",
      "3  positive  Excellent Soundtrack: I truly like this soundt...   \n",
      "4  positive  Remember, Pull Your Jaw Off The Floor After He...   \n",
      "\n",
      "                                    cleaned_features  \n",
      "0  stune even sound track beauti paint seneri min...  \n",
      "1  best soundtrack ever anyth read lot review say...  \n",
      "2  amaz soundtrack favorit music time hand intens...  \n",
      "3  excel soundtrack truli like soundtrack enjoy v...  \n",
      "4  rememb pull jaw floor hear play game know divi...  \n",
      "     labels                                           Features  \\\n",
      "0  positive  Stuning even for the non-gamer: This sound tra...   \n",
      "1  positive  The best soundtrack ever to anything.: I'm rea...   \n",
      "2  positive  Amazing!: This soundtrack is my favorite music...   \n",
      "3  positive  Excellent Soundtrack: I truly like this soundt...   \n",
      "4  positive  Remember, Pull Your Jaw Off The Floor After He...   \n",
      "\n",
      "                                    cleaned_features  \n",
      "0  stune even sound track beauti paint seneri min...  \n",
      "1  best soundtrack ever anyth read lot review say...  \n",
      "2  amaz soundtrack favorit music time hand intens...  \n",
      "3  excel soundtrack truli like soundtrack enjoy v...  \n",
      "4  rememb pull jaw floor hear play game know divi...  \n"
     ]
    }
   ],
   "source": [
    "df_train = clean_data(df_train)\n",
    "df_test = clean_data(df_test)\n",
    "\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the cleaned_features into CountVectorizer , SparseMatrix \n",
    "x_train = cv.fit_transform(df_train.cleaned_features)\n",
    "x_test = cv.fit_transform(df_test.cleaned_features)\n",
    "\n",
    "y_train = df_train['labels'].values\n",
    "y_test = df_test['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nandagopalparamasivam/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X = x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836163836163836\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true = y_test, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
